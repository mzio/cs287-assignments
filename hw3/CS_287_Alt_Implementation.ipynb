{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "CS 287 Alt Implementation.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "metadata": {
        "id": "Ag0-vjntb8Pt",
        "colab_type": "code",
        "outputId": "1980bc2c-e823-476b-effe-f9426b15c8b6",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 326
        }
      },
      "cell_type": "code",
      "source": [
        "!pip install -q torch torchtext spacy opt_einsum\n",
        "!pip install -qU git+https://github.com/harvardnlp/namedtensor\n",
        "!python -m spacy download en\n",
        "!python -m spacy download de"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "  Building wheel for namedtensor (setup.py) ... \u001b[?25ldone\n",
            "\u001b[?25hRequirement already satisfied: en_core_web_sm==2.0.0 from https://github.com/explosion/spacy-models/releases/download/en_core_web_sm-2.0.0/en_core_web_sm-2.0.0.tar.gz#egg=en_core_web_sm==2.0.0 in /usr/local/lib/python3.6/dist-packages (2.0.0)\n",
            "\n",
            "\u001b[93m    Linking successful\u001b[0m\n",
            "    /usr/local/lib/python3.6/dist-packages/en_core_web_sm -->\n",
            "    /usr/local/lib/python3.6/dist-packages/spacy/data/en\n",
            "\n",
            "    You can now load the model via spacy.load('en')\n",
            "\n",
            "Requirement already satisfied: de_core_news_sm==2.0.0 from https://github.com/explosion/spacy-models/releases/download/de_core_news_sm-2.0.0/de_core_news_sm-2.0.0.tar.gz#egg=de_core_news_sm==2.0.0 in /usr/local/lib/python3.6/dist-packages (2.0.0)\n",
            "\n",
            "\u001b[93m    Linking successful\u001b[0m\n",
            "    /usr/local/lib/python3.6/dist-packages/de_core_news_sm -->\n",
            "    /usr/local/lib/python3.6/dist-packages/spacy/data/de\n",
            "\n",
            "    You can now load the model via spacy.load('de')\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "AwwdUiBDcKSh",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torchtext\n",
        "from torchtext.vocab import Vectors, GloVe\n",
        "\n",
        "from namedtensor import ntorch, NamedTensor\n",
        "from namedtensor.text import NamedField\n",
        "\n",
        "import torch.optim as optim\n",
        "\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "\n",
        "from torch.autograd import Variable\n",
        "\n",
        "import matplotlib.pyplot as plt"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "mrtL9COHQFm0",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def save_checkpoint(mod_enc, mod_dec, filename='checkpoint.pth.tar'):\n",
        "    state_dict = {'model_encoder' : mod_enc.state_dict(),\n",
        "                  'model_decoder' : mod_dec.state_dict()}\n",
        "    torch.save(state_dict, filename)\n",
        "    \n",
        "def load_checkpoint(filename='checkpoint.pth.tar'):\n",
        "    state_dict = torch.load(filename)\n",
        "    return state_dict['model_encoder'], state_dict['model_decoder']\n",
        "  \n",
        "def set_parameters(model, sv_model, cuda=True):\n",
        "    for i,p in enumerate(model.parameters()):\n",
        "        p.data = sv_model[list(sv_model)[i]]\n",
        "    model.cuda()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "DCo948jncOVf",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "import torchtext\n",
        "from torchtext import data\n",
        "from torchtext import datasets\n",
        "from torchtext.vocab import Vectors\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch.optim as optim\n",
        "\n",
        "import numpy as np\n",
        "import itertools as it\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "import spacy\n",
        "import time\n",
        "\n",
        "MAX_LEN = 20\n",
        "MIN_FREQ = 5"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "VAmWYW-qcS0D",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "spacy_de = spacy.load('de')\n",
        "spacy_en = spacy.load('en')\n",
        "\n",
        "def tokenize_de(text):\n",
        "    return [tok.text for tok in spacy_de.tokenizer(text)]\n",
        "\n",
        "def tokenize_en(text):\n",
        "    return [tok.text for tok in spacy_en.tokenizer(text)]\n",
        "\n",
        "BOS_WORD = '<s>'\n",
        "EOS_WORD = '</s>'\n",
        "DE = data.Field(tokenize=tokenize_de)\n",
        "\n",
        "# only target needs BOS/EOS:\n",
        "EN = data.Field(tokenize=tokenize_en, init_token = BOS_WORD, eos_token = EOS_WORD) \n",
        "\n",
        "train, val, test = datasets.IWSLT.splits(exts=('.de', '.en'), fields=(DE, EN), \n",
        "                                         filter_pred=lambda x: len(vars(x)['src']) <= MAX_LEN and \n",
        "                                         len(vars(x)['trg']) <= MAX_LEN)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "fe9JyTblcU4U",
        "colab_type": "code",
        "outputId": "1379d04c-32e2-48da-f676-d30821c836db",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 238
        }
      },
      "cell_type": "code",
      "source": [
        "!curl -O https://raw.githubusercontent.com/harvard-ml-courses/cs287-s18/master/HW3/source_test.txt\n",
        "!head source_test.txt"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\n",
            "                                 Dload  Upload   Total   Spent    Left  Speed\n",
            "\r  0     0    0     0    0     0      0      0 --:--:-- --:--:-- --:--:--     0\r  0     0    0     0    0     0      0      0 --:--:-- --:--:-- --:--:--     0\r100 50587  100 50587    0     0   115k      0 --:--:-- --:--:-- --:--:--  115k\n",
            "Als ich in meinen 20ern war , hatte ich meine erste Psychotherapie-Patientin .\n",
            "Ich war Doktorandin und studierte Klinische Psychologie in Berkeley .\n",
            "Sie war eine 26-jährige Frau namens Alex .\n",
            "Und als ich das hörte , war ich erleichtert .\n",
            "Meine Kommilitonin bekam nämlich einen Brandstifter als ersten Patienten .\n",
            "Und ich bekam eine Frau in den 20ern , die über Jungs reden wollte .\n",
            "Das kriege ich hin , dachte ich mir .\n",
            "Aber ich habe es nicht hingekriegt .\n",
            "Arbeit kam später , Heiraten kam später , Kinder kamen später , selbst der Tod kam später .\n",
            "Leute in den 20ern wie Alex und ich hatten nichts als Zeit .\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "wVtGImwQcW1x",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "DE.build_vocab(train.src, min_freq=MIN_FREQ)\n",
        "EN.build_vocab(train.trg, min_freq=MIN_FREQ)\n",
        "\n",
        "pred_set = []\n",
        "for i, line in enumerate(open(\"source_test.txt\"), 1):\n",
        "    words = line.split()# [:-1]\n",
        "    pred_set.append([DE.vocab.stoi[s] for s in words])\n",
        "\n",
        "device = torch.device('cuda')\n",
        "train_iter, val_iter, test_iter = data.BucketIterator.splits((train, val, test), batch_size=32, device=device,\n",
        "                                                  repeat=False, sort_key=lambda x: len(x.src))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "wqBFAFwUcYhU",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "batch = next(iter(test_iter))\n",
        "# sent_inspect(batch,4)\n",
        "def sent_inspect(batch, idx=0):\n",
        "    print(\"Source\")\n",
        "    print(' '.join([DE.vocab.itos[w] for w in batch.src.data[:,idx]]))\n",
        "    print(\"Target\")\n",
        "    print(' '.join([EN.vocab.itos[w] for w in batch.trg.data[:,idx]]))\n",
        "# print(DE.vocab.stoi['<pad>'])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "YPKf5huWcaXr",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Models"
      ]
    },
    {
      "metadata": {
        "id": "s2CZlj0Bcb2e",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "class EmbeddingLM(nn.Module):\n",
        "    def __init__(self, TEXT, dropout=0.0, max_embedding_norm=None, embedding_size=1000):\n",
        "        super(EmbeddingLM, self).__init__()\n",
        "        self.dropout_prob = dropout\n",
        "        self.dropout = nn.Dropout(self.dropout_prob)\n",
        "        \n",
        "        self.vocab_size = len(TEXT.vocab)\n",
        "        self.embedding_dim = embedding_size\n",
        "        self.embeddings = nn.Embedding(self.vocab_size, self.embedding_dim, \n",
        "                                       max_norm=max_embedding_norm)\n",
        "\n",
        "class EncoderLSTM(EmbeddingLM):\n",
        "    def __init__(self, TEXT, hidden_size=500, num_layers=2,\n",
        "                 bidirectional=False, **kwargs):\n",
        "        super(EncoderLSTM, self).__init__(TEXT, **kwargs)\n",
        "        self.hidden_size = hidden_size\n",
        "        self.num_layers = num_layers\n",
        "        self.bidirectional = bidirectional\n",
        "        self.lstm = nn.LSTM(input_size=self.embedding_dim, hidden_size=self.hidden_size,\n",
        "                            num_layers=self.num_layers,\n",
        "                            dropout=self.dropout_prob, batch_first=True,\n",
        "                            bidirectional=self.bidirectional)\n",
        "\n",
        "        \n",
        "    def forward(self, input, hidden):\n",
        "        x = self.embeddings(input)  # batch size, sentence len, embedding dim\n",
        "        x = self.dropout(x)\n",
        "        output, hidden = self.lstm(x, hidden)\n",
        "        return output, hidden  # batch, sentence len, hidden size * 1 or 2\n",
        "\n",
        "\n",
        "class DecoderLSTM(EncoderLSTM):\n",
        "    \"\"\"Inherit same architecture as encoder, but reversed\"\"\"\n",
        "    def __init__(self, TEXT, context_size=1, bidirectional_encoder=False, **kwargs):\n",
        "        super(DecoderLSTM, self).__init__(TEXT, **kwargs)\n",
        "        self.context_size = context_size\n",
        "        self.encoder_dirs = 2 if bidirectional_encoder else 1\n",
        "        input_dim = self.context_size * self.num_layers * self.encoder_dirs + 1\n",
        "        self.output = nn.Linear(input_dim * self.hidden_size, self.vocab_size)\n",
        "\n",
        "    def forward(self, input, hidden, context):\n",
        "        \"\"\":context: tuple (h, c) of hidden and cell states from t-1 of encoder\"\"\"\n",
        "        x = self.embeddings(input)\n",
        "        x = F.relu(x)\n",
        "        output, hidden = self.lstm(x, hidden)\n",
        "\n",
        "        if self.context_size:\n",
        "            context_var = torch.cat(context[:self.context_size])\n",
        "            batch_size = context_var.size(1)\n",
        "            sentence_len = output.size(1)\n",
        "\n",
        "            # Convert this to named version? rn [batch_size, 1, hidden_size * context_size]\n",
        "            context_var = context_var.permute(1, 0, 2).contiguous().view(batch_size, 1, -1)\n",
        "            context_var = context_var.expand(-1, sentence_len, -1)\n",
        "            output = torch.cat((output, context_var), dim=2)\n",
        "\n",
        "        output = self.output(output)\n",
        "        output = F.log_softmax(output, dim=2)\n",
        "        return output, hidden\n",
        "\n",
        "\n",
        "class DecoderAttn(EncoderLSTM):\n",
        "    def __init__(self, TEXT, bidirectional_encoder=False, tie_weights=False,\n",
        "                 linear_encoder=0, **kwargs):\n",
        "        super(DecoderAttn, self).__init__(TEXT, **kwargs)\n",
        "        print('Using final MLP')\n",
        "        self.encoder_dirs = 2 if bidirectional_encoder else 1\n",
        "\n",
        "        dims = self.encoder_dirs  \n",
        "        self.output_decoder = nn.Linear(self.hidden_size, self.vocab_size)\n",
        "        self.output_context = nn.Linear(dims * self.hidden_size, self.vocab_size)\n",
        "\n",
        "        self.linear_encoder = linear_encoder\n",
        "        if self.linear_encoder > 0:\n",
        "            self.attn_linear = nn.Linear(self.encoder_dirs * self.linear_encoder,\n",
        "                                         self.hidden_size)\n",
        "\n",
        "        if tie_weights:\n",
        "            if self.hidden_size != self.embedding_dim:\n",
        "                raise ValueError('Tied weights require hidden size to equal embedding dimension!')\n",
        "            self.output_decoder.weight = self.embeddings.weight\n",
        "        \n",
        "    def forward(self, input, hidden, encoded_output, mask_ix=None):\n",
        "        embedding = self.embeddings(input)\n",
        "        embedding = self.dropout(embedding)\n",
        "        decoder_output, hidden = self.lstm(embedding, hidden)\n",
        "        \n",
        "        # Attention\n",
        "        if self.linear_encoder > 0:\n",
        "            output_linear_encoder = self.attn_linear(encoded_output)\n",
        "        else:\n",
        "            output_linear_encoder = encoded_output\n",
        "\n",
        "        # output_encoder_prm is [batch_size, hidden_size, sentence_len (src)] <- TODO: Named\n",
        "        output_encoder_perm = output_linear_encoder.permute(0, 2, 1)\n",
        "        products = torch.bmm(decoder_output, output_encoder_perm)\n",
        "\n",
        "        # mask_ix is [batch_size, sentence_len_src]\n",
        "        if mask_ix is not None:\n",
        "            mask_ix = Variable(torch.Tensor([np.inf])) * mask_ix\n",
        "            mask_ix[mask_ix != mask_ix] = 0\n",
        "            products = products - torch.unsqueeze(mask_ix, 1)\n",
        "        \n",
        "        product_softmax = F.softmax(products, dim=2)\n",
        "        context = torch.bmm(product_softmax, encoded_output)\n",
        "\n",
        "        output_1 = self.output_decoder(self.dropout(decoder_output))\n",
        "        output_2 = self.output_context(self.dropout(context))\n",
        "        \n",
        "        output = output_1 + output_2\n",
        "        output = F.log_softmax(output, dim=2)\n",
        "        \n",
        "        return output, hidden, product_softmax "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "RumLO_oPcnZM",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Training Stuff"
      ]
    },
    {
      "metadata": {
        "id": "PgmK45fkchfX",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "class TrainTestBase(object):\n",
        "    \"\"\"\n",
        "    Parent class for training and evaluation\n",
        "    :models: should be list of [encoder, decoder]\n",
        "    \"\"\"\n",
        "    def __init__(self, models, TEXT_SRC, TEXT_TRG, mask_src=False,\n",
        "                 attention=False, reverse_encoder_input=False, cuda=True):\n",
        "        self.TEXT_SRC = TEXT_SRC\n",
        "        self.TEXT_TRG = TEXT_TRG\n",
        "        self.padding_src = TEXT_SRC.vocab.stoi['<pad>']\n",
        "        self.padding_trg = TEXT_TRG.vocab.stoi['<pad>']\n",
        "\n",
        "        self.models = models\n",
        "        self.mask_src = mask_src\n",
        "        self.use_attention = attention\n",
        "        self.record_attention = False\n",
        "        self.reverse_encoder_input = reverse_encoder_input\n",
        "        self.cuda = cuda and torch.cuda.is_available()\n",
        "        if self.cuda:\n",
        "            print('Using CUDA')\n",
        "\n",
        "    def get_src_and_trg(self, batch):\n",
        "        if self.reverse_encoder_input:\n",
        "            src_data = torch.t(batch.src.data)\n",
        "            ix_rev = torch.LongTensor(np.arange(src_data.size(1) - 1, -1, -1))\n",
        "            src = torch.index_select(torch.t(batch.src.data), dim=1,\n",
        "                                     index=ix_rev)\n",
        "            src = src.contiguous()\n",
        "        else:\n",
        "            src = torch.t(batch.src.data).contiguous()\n",
        "        trg = torch.t(batch.trg.data)\n",
        "        trg_feature = trg[:, :-1].contiguous()\n",
        "        trg_label = trg[:, 1:].contiguous()\n",
        "        return (src, trg_feature, trg_label)\n",
        "\n",
        "    def initial_hidden(self, batch_size, model_ix):\n",
        "        num_directions = 2 if self.models[model_ix].bidirectional else 1\n",
        "        return torch.zeros(self.models[model_ix].num_layers * num_directions, \n",
        "                           batch_size, self.models[model_ix].hidden_size)\n",
        "\n",
        "    def init_hidden(self, batch_size, zeros=True, model_ix=0):\n",
        "        if (self.prev_hidden is not None) and (not zeros):\n",
        "            hidden = self.prev_hidden\n",
        "        else:\n",
        "            hidden = (self.initial_hidden(batch_size, model_ix) for i in range(2))\n",
        "        if self.cuda:\n",
        "            hidden = tuple(h.cuda() for h in hidden)\n",
        "        return tuple(Variable(h) for h in hidden)\n",
        "\n",
        "    def init_model_inputs(self, batch, **kwargs):\n",
        "        if self.cuda:\n",
        "            src, trg_feature, trg_label = tuple(x.cuda() for x in self.get_src_and_trg(batch))\n",
        "        else:\n",
        "            src, trg_feature, trg_label = self.get_src_and_trg(batch)\n",
        "\n",
        "        assert batch.src.size(1) == batch.trg.size(1)\n",
        "        hidden = self.init_hidden(batch.src.size(1), **kwargs)\n",
        "        return (Variable(src), Variable(trg_feature), Variable(trg_label), hidden)\n",
        "\n",
        "    def init_epoch(self):\n",
        "        self.prev_hidden = None\n",
        "\n",
        "    def set_prev_hidden(self, hidden):\n",
        "        if self.models[1].encoder_dirs == 2:\n",
        "            self.prev_hidden = tuple(h[self.models[0].num_layers:, :, :] for h in hidden)\n",
        "        else:\n",
        "            self.prev_hidden = hidden\n",
        "\n",
        "    def get_attn_marsk(self, src):\n",
        "        if self.mask_src:\n",
        "            mask_padding = torch.eq(src, self.padding_src).type(torch.FloatTensor)\n",
        "            mask_padding = mask_padding.cuda() if self.cuda else mask_padding\n",
        "            return mask_padding\n",
        "        else:\n",
        "            return None\n",
        "        \n",
        "    def run_model(self, batch, mode='mean'):\n",
        "        src, trg_feature, trg_label, hidden = self.init_model_inputs(batch, zeros=True, model_ix=0)\n",
        "\n",
        "        encoded_output, encoded_hidden = self.models[0](src, hidden)\n",
        "        self.set_prev_hidden(encoded_hidden)\n",
        "            \n",
        "        if self.use_attention:\n",
        "            mask_padding = self.get_attn_marsk(src)\n",
        "            decoder_output, decoder_hidden, decoder_attn = self.models[1](\n",
        "                trg_feature, self.prev_hidden, encoded_output, mask_padding)\n",
        "            if self.record_attention:\n",
        "                _, pred = torch.topk(decoder_output, k=1, dim=2)\n",
        "                self.attn_log.append((decoder_attn, src, pred.squeeze(), trg_label))\n",
        "        else:\n",
        "            decoder_output, decoder_hidden = self.models[1](\n",
        "                trg_feature, self.prev_hidden, encoded_hidden)\n",
        "            \n",
        "        self.prev_hidden = decoder_hidden\n",
        "        return self.nll_loss(decoder_output, trg_label, mode=mode)\n",
        "\n",
        "    def nll_loss(self, log_probs, output, mode='mean', **kwargs):\n",
        "        batch_size = log_probs.size(0)\n",
        "        typing = torch.cuda.FloatTensor if self.cuda else torch.FloatTensor\n",
        "        sentence_len = torch.sum((output != self.padding_trg).type(typing)) / batch_size\n",
        "\n",
        "        log_probs_ = log_probs.view(-1, log_probs.size(2))\n",
        "        output_ = output.view(-1)\n",
        "        if mode == 'mean':\n",
        "            return F.nll_loss(log_probs_, output_, ignore_index=self.padding_trg, **kwargs) * sentence_len\n",
        "        elif mode == 'sum':\n",
        "            return F.nll_loss(log_probs_, output_, ignore_index=self.padding_trg, size_average=False)\n",
        "\n",
        "            \n",
        "class ModelEval(TrainTestBase):\n",
        "    def __init__(self, models, TEXT_SRC, TEXT_TRG, record_attention=False,\n",
        "                 visualize_freq=None, **kwargs):\n",
        "        \"\"\"\n",
        "        Validation class. Requires matplotlib for the visualization\n",
        "        \"\"\"\n",
        "        super(ModelEval, self).__init__(models, TEXT_SRC, TEXT_TRG,\n",
        "                                           **kwargs)\n",
        "        self.record_attention = record_attention\n",
        "        self.visualize_freq = visualize_freq\n",
        "        \n",
        "    def init_epoch(self):\n",
        "        super(ModelEval, self).init_epoch()\n",
        "        self.attn_log = list()\n",
        "        \n",
        "    def visualize_attn(self, decoder_attn_sample, src_sample, pred_sample,\n",
        "                       trg_label=None, save_name=None):\n",
        "        attn = decoder_attn_sample.cpu().data.numpy()\n",
        "        src_words = np.array(list(map(lambda x: self.TEXT_SRC.vocab.itos[x], \n",
        "                                      src_sample.cpu().data.numpy())))\n",
        "        pred_words = np.array(list(map(lambda x: self.TEXT_TRG.vocab.itos[x], \n",
        "                                       pred_sample.cpu().data.numpy())))\n",
        "        if not trg_label is None:\n",
        "            trg_cpu = trg_label.cpu().data.numpy()\n",
        "            trg_words = np.array(list(map(lambda x : self.TEXT_TRG.vocab.itos[x],\n",
        "                                         trg_cpu)))\n",
        "            pred_words = np.array(['%s (%s)' % (pred_words[i], trg_words[i]) for \\\n",
        "                                   i in range(pred_words.shape[0])])\n",
        "            pad_ix = np.where(trg_words == '<pad>')[0]\n",
        "            if len(pad_ix):\n",
        "                clip_len = pad_ix[0]\n",
        "                trg_words = trg_words[:clip_len]\n",
        "                pred_words = pred_words[:clip_len]\n",
        "                attn = attn[:clip_len, :]\n",
        "        \n",
        "        # Visualizations\n",
        "        fig, ax = plt.subplots()\n",
        "        ax.imshow(attn, cmap='gray')\n",
        "        plt.xticks(range(len(src_words)), src_words, rotation='vertical')\n",
        "        plt.yticks(range(len(pred_words)), pred_words)\n",
        "\n",
        "        ax.xaxis.tick_top()\n",
        "\n",
        "        if not save_name is None:\n",
        "            plt.savefig(save_name)\n",
        "        plt.show()\n",
        "\n",
        "    def evaluate(self, test_iter, num_iter=None):\n",
        "        start_time = time.time()\n",
        "        for model in self.models:\n",
        "            model.eval()\n",
        "\n",
        "        nll_sum = 0\n",
        "        nll_count = 0\n",
        "\n",
        "        self.init_epoch()\n",
        "        test_iter.init_epoch()\n",
        "\n",
        "        for i, batch in enumerate(test_iter):\n",
        "            nll_count += batch.trg.data.numel()\n",
        "            loss = self.run_model(batch, mode='sum')\n",
        "            nll_sum += loss.data.item()\n",
        "            \n",
        "            if self.visualize_freq and i % self.visualize_freq == 0:\n",
        "                sample = self.attn_log[-1]\n",
        "                self.visualize_attn(sample[0][0], sample[1][0], sample[2][0])\n",
        "            if not num_iter is None and i > num_iter:\n",
        "                break\n",
        "                        \n",
        "        for model in self.models:\n",
        "            model.train()\n",
        "        \n",
        "        print('Validation time: %f seconds' % (time.time() - start_time))\n",
        "        return np.exp(nll_sum / nll_count)\n",
        "    \n",
        "    # Performs beam search\n",
        "    def beam_search_predict(self, sentence, ref_beam, ref_vocab, \n",
        "                            beam_size=100, pred_len=3, pred_num=None,\n",
        "                            ignore_eos=False, translate=False):\n",
        "        \"\"\"Beam search implementation for selecting viable translations\"\"\"\n",
        "        if pred_num is None:\n",
        "            pred_num = beam_size\n",
        "        \n",
        "        # [sentence_len]\n",
        "        tensor_sentence = torch.LongTensor(sentence)\n",
        "        if self.reverse_encoder_input:\n",
        "            ix_rev = torch.LongTensor(np.arange(tensor_sentence.size(0) - 1, -1, -1))\n",
        "            tensor_sentence = torch.index_select(tensor_sentence, dim=0,\n",
        "                                          index=ix_rev)\n",
        "        if self.cuda:\n",
        "            tensor_sentence = tensor_sentence.cuda()   \n",
        "\n",
        "        src = Variable(tensor_sentence.view(1, -1).expand(beam_size, -1))\n",
        "        hidden = self.init_hidden(beam_size, zeros=True)\n",
        "        \n",
        "        # For attention, will use encoder_output (not otherwise)\n",
        "        encoder_output, encoder_hidden = self.models[0](src, hidden)\n",
        "        self.set_prev_hidden(encoder_hidden)\n",
        "        \n",
        "        sos_token = self.TEXT_TRG.vocab.stoi['<s>']  # Start with SOS  \n",
        "        self.current_beams = (sos_token * torch.ones(beam_size, 1)).type(torch.LongTensor)\n",
        "        self.current_beam_vals = torch.zeros(beam_size, 1).type(torch.FloatTensor)\n",
        "        if self.cuda:\n",
        "            self.current_beams = self.current_beams.cuda()\n",
        "            self.current_beam_vals = self.current_beam_vals.cuda()\n",
        "        self.current_beams = Variable(self.current_beams)\n",
        "        self.current_beam_vals = Variable(self.current_beam_vals)\n",
        "\n",
        "        if translate:\n",
        "            final_preds = list()\n",
        "\n",
        "        for i in range(pred_len):\n",
        "            if translate:\n",
        "                (ref_beam, ref_vocab) = self.create_ref_arrays(self.current_beams.size(0))\n",
        "\n",
        "            current_sentence = self.current_beams[:, i:i+1]\n",
        "            if self.use_attention:\n",
        "                mask_padding = self.get_attn_marsk(src)\n",
        "\n",
        "                decoder_output, decoder_hidden, decoder_attn = self.models[1](\n",
        "                    current_sentence, self.prev_hidden, encoder_output[:self.current_beams.size(0)], mask_padding)\n",
        "                if self.record_attention:\n",
        "                    _, pred = torch.topk(decoder_output, k=1, dim=2)\n",
        "                    self.attn_log.append((decoder_attn, src, pred.squeeze(), None))\n",
        "            else:\n",
        "                decoder_output, decoder_hidden = self.models[1](\n",
        "                    current_sentence, self.prev_hidden, encoder_hidden)\n",
        "            self.prev_hidden = decoder_hidden\n",
        "            \n",
        "            decoder_output = decoder_output.squeeze()\n",
        "\n",
        "            if ignore_eos:  # EOS tokens  \n",
        "                eos_token = self.TEXT_TRG.vocab.stoi['</s>']\n",
        "                decoder_output[:, eos_token] = -np.inf\n",
        "\n",
        "            decoder_output = decoder_output + self.current_beam_vals\n",
        "\n",
        "            if i == 0:\n",
        "                decoder_output = decoder_output[0, :]\n",
        "            else:\n",
        "                decoder_output = decoder_output.view(-1)\n",
        "                \n",
        "            topk_dec, topk_ix = torch.topk(decoder_output, k=beam_size)\n",
        "            prev_ix = torch.index_select(ref_beam, dim=0, index=topk_ix)\n",
        "            prevs = torch.index_select(self.current_beams, dim=0, index=prev_ix)\n",
        "\n",
        "            # Update hidden to reflect previous sentences picked\n",
        "            self.prev_hidden = tuple(torch.index_select(\n",
        "                    self.prev_hidden[j], dim=1, index=prev_ix) for j in range(len(self.prev_hidden)))\n",
        "            \n",
        "            # Update current baem values  \n",
        "            self.current_beam_vals = topk_dec.view(-1, 1)\n",
        "            nexts = torch.index_select(ref_vocab, dim=0, index=topk_ix).view(-1, 1)\n",
        "            self.current_beams = torch.cat((prevs, nexts), dim=1)\n",
        "\n",
        "            if translate:\n",
        "                sentences_ = list()\n",
        "                eos_token = self.TEXT_TRG.vocab.stoi['</s>']\n",
        "                for i in range(self.current_beams.size(0)):\n",
        "                    if self.current_beams[i,-1].data.item() == eos_token:\n",
        "                        final_preds.append(self.current_beams[i,:])\n",
        "                    else:\n",
        "                        sentences_.append(i)\n",
        "                keep_ix = Variable(torch.LongTensor(sentences_))\n",
        "                keep_ix = keep_ix.cuda() if self.cuda else keep_ix\n",
        "\n",
        "                # Now reselect\n",
        "                if len(sentences_) > 100 or len(keep_ix) == 0:\n",
        "                    return final_preds           \n",
        "                self.current_beams = torch.index_select(self.current_beams, 0, keep_ix)\n",
        "                self.current_beam_vals = torch.index_select(self.current_beam_vals, 0, keep_ix)\n",
        "                self.prev_hidden = tuple(torch.index_select(self.prev_hidden[j], 1, keep_ix) \n",
        "                                         for j in range(len(self.prev_hidden)))\n",
        "\n",
        "        if translate:\n",
        "            return final_preds\n",
        "        return self.current_beams\n",
        "    \n",
        "    def escape(self, l):\n",
        "        return l.replace(\"\\\"\", \"<quote>\").replace(\",\", \"<comma>\")\n",
        "\n",
        "    def create_ref_arrays(self, beam_size):\n",
        "        # Keep track of ix for expanding beams and vocab\n",
        "        trg_vocab_size = len(self.TEXT_TRG.vocab)\n",
        "        ref_beam = torch.LongTensor(np.arange(beam_size)).view(-1, 1).expand(-1, trg_vocab_size)\n",
        "        ref_beam = ref_beam.contiguous().view(-1)\n",
        "        ref_beam = ref_beam.cuda() if self.cuda else ref_beam\n",
        "        ref_beam = Variable(ref_beam)\n",
        "        \n",
        "        ref_vocab = torch.LongTensor(np.arange(trg_vocab_size)).view(1, -1).expand(beam_size, -1)\n",
        "        ref_vocab = ref_vocab.contiguous().view(-1)\n",
        "        ref_vocab = ref_vocab.cuda() if self.cuda else ref_vocab\n",
        "        ref_vocab = Variable(ref_vocab)\n",
        "        return (ref_beam, ref_vocab)\n",
        "    \n",
        "    def create_text(self, word_ids, src, is_variable=False):\n",
        "        \"\"\":src: True or False specifying what language\"\"\"\n",
        "        TEXT = self.TEXT_SRC if src else self.TEXT_TRG\n",
        "        if is_variable:\n",
        "            words = [TEXT.vocab.itos[word_ids[k].data.item()] for k in range(1, len(word_ids))]\n",
        "        else:\n",
        "            words = [TEXT.vocab.itos[word_ids[k]] for k in range(1, len(word_ids))]\n",
        "        return ' '.join(words)\n",
        "        \n",
        "    \n",
        "    def view_predictions(self, batch_src, batch_trg, batch_preds):\n",
        "        for i,sent in enumerate(batch_src):\n",
        "            if i > 10:\n",
        "                break\n",
        "            words_src = self.create_text(sent, True)\n",
        "            words_trg = self.create_text(batch_trg[i], False)\n",
        "            words_pred_list = []\n",
        "            for j in range(len(batch_preds[i])):\n",
        "                words_pred_list.append(self.create_text(batch_preds[i][j], False,\n",
        "                                                       is_variable=True))\n",
        "            for w in words_pred_list:\n",
        "                print(w)\n",
        "            \n",
        "        \n",
        "    def predict(self, test_set, fname='predictions.txt', num_cands=100, pred_len=3,\n",
        "                beam_size=100, ignore_eos=False, translate=False):\n",
        "        start_time = time.time()\n",
        "        for model in self.models:\n",
        "            model.eval()\n",
        "\n",
        "        (ref_beam, ref_vocab) = self.create_ref_arrays(beam_size)\n",
        "            \n",
        "        self.init_epoch()\n",
        "        predictions = []\n",
        "        for i, sentence in enumerate(test_set):\n",
        "            # [pred_num, pred_len] tensor\n",
        "            translations = self.beam_search_predict(sentence, ref_beam=ref_beam, \n",
        "                                                    ref_vocab=ref_vocab, pred_len=pred_len,\n",
        "                                                    beam_size=beam_size, ignore_eos=ignore_eos,\n",
        "                                                    translate=translate)\n",
        "            predictions.append(translations)            \n",
        "        if translate:\n",
        "            return predictions\n",
        "            \n",
        "        print('Writing predictions to %s' % fname)\n",
        "        with open(fname, 'w') as fout:\n",
        "            print('id,Predicted', file=fout)\n",
        "            for i, preds in enumerate(predictions):\n",
        "                candidates = []\n",
        "                for j in range(num_cands):\n",
        "                    words = [self.TEXT_TRG.vocab.itos[preds[j,k].data.item()] for k in range(1, pred_len + 1)]\n",
        "                    sent = '|'.join(self.escape(l) for l in words)\n",
        "                    candidates.append(sent)\n",
        "                print('%d,%s' % (i, ' '.join(candidates)), file=fout)\n",
        "        print('Computing predictions took %f seconds' % (time.time() - start_time))\n",
        "        \n",
        "        # Wrap model.eavl\n",
        "        for model in self.models:\n",
        "            model.train()\n",
        "            \n",
        "\n",
        "    \n",
        "class ModelTrain(TrainTestBase):\n",
        "    def __init__(self, models, TEXT_SRC, TEXT_TRG, lr=0.1, optimizer=optim.SGD, \n",
        "                 lrn_decay=None, lrn_decay_force=np.inf, lrn_decay_rate=0.1,\n",
        "                 clip_norm=10, **kwargs):\n",
        "        '''\n",
        "        Class to train models.  \n",
        "        :lr_decay_type: type of learning rate decay, pick 'adaptive' or 'linear'\n",
        "        '''\n",
        "        super(NMTTrainer, self).__init__(models, TEXT_SRC, TEXT_TRG, **kwargs)\n",
        "\n",
        "        self.base_lr = lr\n",
        "        self.optimizer_type = optimizer\n",
        "        self.init_optimizers()  # Optimizer for each model\n",
        "\n",
        "        # Learning rate decay\n",
        "        self.lr_decay_type = lrn_decay\n",
        "        self.lr_decay_force = lrn_decay_force\n",
        "\n",
        "        if self.lr_decay_type is None or self.lr_decay_type == 'adaptive':\n",
        "            self.lr_lambda = lambda i : 1\n",
        "        elif self.lr_decay_type == 'linear':\n",
        "            decay_rate = lrn_decay_rate\n",
        "            self.lr_lambda = lambda i : 1 / (1 + (i - 6) * decay_rate) if i > 6 else 1\n",
        "        \n",
        "        self.schedulers = [optim.lr_scheduler.LambdaLR(optimizer,\n",
        "            self.lr_lambda) for optimizer in self.optimizers]\n",
        "\n",
        "        self.clip_norm = clip_norm\n",
        "        self.restart_logs()\n",
        "        if self.cuda:\n",
        "            for model in self.models:\n",
        "                model.cuda()\n",
        "                \n",
        "    def init_optimizers(self):\n",
        "        self.optimizers = [self.optimizer_type(filter(lambda p : p.requires_grad,\n",
        "                                                      model.parameters()),\n",
        "                                               lr = self.base_lr) for \\\n",
        "                           model in self.models]\n",
        "\n",
        "    def restart_logs(self):\n",
        "        self.training_losses = list()\n",
        "        self.training_norms = list()\n",
        "        self.val_performance = list()\n",
        "\n",
        "    def get_loss_data(self, loss):\n",
        "        if self.cuda:\n",
        "            return loss.data.cpu().numpy()\n",
        "        else:\n",
        "            return loss.data.numpy()[0]\n",
        "\n",
        "    def record_updates(self, loss, norm):\n",
        "        self.training_norms.append(norm)\n",
        "        self.training_losses.append(loss)\n",
        "\n",
        "    def clip_norms(self):\n",
        "        if self.clip_norm > 0:\n",
        "            parameters = tuple()\n",
        "            for model in self.models:\n",
        "                parameters += tuple(model.parameters())\n",
        "                \n",
        "            norm = nn.utils.clip_grad_norm(parameters, self.clip_norm)\n",
        "        else:\n",
        "            norm = -1\n",
        "        return norm\n",
        "\n",
        "    def train_batch(self, batch, **kwargs):\n",
        "        for model in self.models:\n",
        "            model.zero_grad()\n",
        "        loss = self.run_model(batch)\n",
        "        loss.backward()\n",
        "\n",
        "        norm = self.clip_norms()\n",
        "\n",
        "        loss_data = self.get_loss_data(loss)\n",
        "\n",
        "        if kwargs.get('verbose', False):\n",
        "            self.record_updates(loss_data, norm)\n",
        "\n",
        "        for optimizer in self.optimizers:\n",
        "            optimizer.step()\n",
        "\n",
        "        return loss_data, norm\n",
        "\n",
        "    def init_parameters(self):\n",
        "        for model in self.models:\n",
        "            for p in model.parameters():\n",
        "                p.data.uniform_(-0.05, 0.05)\n",
        "\n",
        "    def train(self, train_iter, eval_=None, val_iter=None,\n",
        "              save_model_fname=None, init_parameters=True, **kwargs):\n",
        "        self.restart_logs()\n",
        "        start_time = time.time()\n",
        "        print(\"Initializing parameters status: \", init_parameters)\n",
        "        if init_parameters:\n",
        "            self.init_parameters()\n",
        "\n",
        "        train_iter.init_epoch()\n",
        "\n",
        "        for epoch in range(kwargs.get('num_iter', 100)):\n",
        "            self.init_epoch()\n",
        "            for model in self.models:\n",
        "                model.train()\n",
        "                \n",
        "            # Learning rate decay?\n",
        "            if self.lr_decay_type == 'adaptive':\n",
        "                if (epoch > 2 and self.val_performance[-1] > self.val_performance[-2]) or (epoch >= self.lr_decay_force):\n",
        "                    self.base_lr = self.base_lr / 2\n",
        "                    self.init_optimizers()  \n",
        "                    print('Decay LR to %f' % self.base_lr)\n",
        "            else:\n",
        "                for scheduler in self.schedulers:\n",
        "                    scheduler.step()\n",
        "\n",
        "            train_iter = iter(train_iter)\n",
        "\n",
        "            for batch in train_iter:\n",
        "                result_loss, result_norm = self.train_batch(batch, **kwargs)\n",
        "\n",
        "            if epoch % kwargs.get('skip_iter', 1) == 0:\n",
        "                if not kwargs.get('verbose', False):\n",
        "                    self.record_updates(result_loss, result_norm)\n",
        "\n",
        "            print('Epoch %d, loss: %f, norm: %f, elapsed: %f, lr: %f' \\\n",
        "                  % (epoch, np.mean(self.training_losses[-10:]),\n",
        "                     np.mean(self.training_norms[-10:]),\n",
        "                     time.time() - start_time, self.base_lr)) \n",
        "                    \n",
        "            if (eval_ is not None) and (val_iter is not None):\n",
        "                self.val_performance.append(eval_.evaluate(val_iter))\n",
        "                print('Validation set metric: %f' % \\\n",
        "                      self.val_performance[-1])\n",
        "\n",
        "            if save_model_fname is not None:\n",
        "                path_name = save_model_fname + '.epoch_%d.ckpt.tar' % epoch\n",
        "                print('Saving model')\n",
        "                save_checkpoint(self.models[0], self.models[1], path_name)\n",
        "\n",
        "        if len(self.val_performance) >= 1:  # Check for final submission, but probably will stop before this\n",
        "            print('FINAL VAL PERF', self.val_performance[-1])\n",
        "            return self.val_performance[-1]\n",
        "        return -1"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "k-tJJdp3Z6fe",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### Call these to train new model  \n",
        "Better to load saved model below"
      ]
    },
    {
      "metadata": {
        "id": "5mPud26iuGwB",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# device = torch.device('cuda')\n",
        "# train_iter, val_iter = data.BucketIterator.splits((train, val), batch_size=32, device=device,\n",
        "#                                                   repeat=False, sort_key=lambda x: len(x.src))\n",
        "# bs_encoder = Encod`erLSTM(DE, hidden_size=500, num_layers=4, embedding_size=500)\n",
        "# at_decoder = DecoderAttn(EN, hidden_size=500, num_layers=4, embedding_size=500)\n",
        "# trainer = ModelTrain([bs_encoder, bs_decoder], DE, EN, lr=0.7, \n",
        "#                      lr_decay_type='adaptive', reverse_encoder_input=False)\n",
        "# evaluator = ModelEval([bs_encoder, bs_decoder], DE, EN, reverse_encoder_input=False)\n",
        "# trainer.train(train_iter, val_iter=val_iter,eval_=evaluator)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "vWgxCYs2JcSN",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "train_iter, val_iter = data.BucketIterator.splits((train, val), batch_size=32, device=device,\n",
        "                                                  repeat=False, sort_key=lambda x: len(x.src))\n",
        "bs_encoder = EncoderLSTM(DE, hidden_size=650, num_layers=4, embedding_size=650, \n",
        "                         bidirectional=True, dropout=0.35)\n",
        "at_decoder = DecoderAttn(EN, hidden_size=650, num_layers=4, embedding_size=650, \n",
        "                         dropout=0.35, tie_weights=True, linear_encoder=650, \n",
        "                         bidirectional_encoder=True)\n",
        "trainer = ModelTrain([bs_encoder, at_decoder], DE, EN, lr=1.2, \n",
        "                     lr_decay_type='adaptive', attention=True,\n",
        "                     clip_norm=5)\n",
        "evaluator = ModelEval([bs_encoder, at_decoder], DE, EN, attention=True,\n",
        "                        record_attention=False)\n",
        "trainer.train(train_iter, verbose=True, eval_=evaluator, val_iter=val_iter,\n",
        "              save_model_fname='attn', num_iter=20)"
      ]
    },
    {
      "metadata": {
        "id": "6-Hm5qrgZ973",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### Load saved model for prediction"
      ]
    },
    {
      "metadata": {
        "id": "YVIup9EXLFSx",
        "colab_type": "code",
        "outputId": "1074da06-df96-4e38-f70d-3781f766d7be",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 85
        }
      },
      "cell_type": "code",
      "source": [
        "ld_enc, ld_dec = load_checkpoint('attn.epoch_10.ckpt.tar')\n",
        "ld_encoder = EncoderLSTM(DE, hidden_size=650, num_layers=4, embedding_size=650, \n",
        "                         bidirectional=True, dropout=0.35)\n",
        "ld_decoder = DecoderAttn(EN, hidden_size=650, num_layers=4, embedding_size=650, \n",
        "                         dropout=0.35, tie_weights=False, linear_encoder=650, \n",
        "                         bidirectional_encoder=True)\n",
        "set_parameters(ld_encoder, ld_enc)\n",
        "set_parameters(ld_decoder, ld_dec)\n",
        "evaluator = ModelEval([ld_encoder, ld_decoder], DE, EN, attention=True,\n",
        "                        record_attention=False)\n",
        "evaluator.predict(pred_set, fname='predictions_100.txt', beam_size=100, ignore_eos=True)"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using final MLP\n",
            "Using CUDA\n",
            "Writing predictions to predictions_100.txt\n",
            "Computing predictions took 101.279886 seconds\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "Gywkoei9bplt",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### Call following for visualization"
      ]
    },
    {
      "metadata": {
        "id": "g-LBfVUzbI3X",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 139
        },
        "outputId": "97b63e2f-10d6-4fa5-a1ef-bac8a4840719"
      },
      "cell_type": "code",
      "source": [
        "def load_validate_model(fn):\n",
        "    ld_enc, ld_dec = load_checkpoint(fn)\n",
        "    ld_encoder = EncoderLSTM(DE, hidden_size=650, num_layers=4, embedding_size=650, \n",
        "                             bidirectional=True, dropout=0.35)\n",
        "    ld_decoder = DecoderAttn(EN, hidden_size=650, num_layers=4, embedding_size=650, dropout=0.35,\n",
        "                             tie_weights=False, linear_encoder=650,\n",
        "                             bidirectional_encoder=True)\n",
        "    set_parameters(ld_encoder, ld_enc)\n",
        "    set_parameters(ld_decoder, ld_dec)\n",
        "    evaluator = ModelEval([ld_encoder, ld_decoder], DE, EN, attention=True,\n",
        "                          record_attention=True)\n",
        "    print(evaluator.evaluate(val_iter))\n",
        "    return evaluator\n",
        "evaluator=load_validate_model('attn.epoch_10.ckpt.tar')"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using final MLP\n",
            "Using CUDA\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/torch/nn/_reduction.py:49: UserWarning: size_average and reduce args will be deprecated, please use reduction='sum' instead.\n",
            "  warnings.warn(warning.format(ret))\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Validation time: 1.257690 seconds\n",
            "4.483508558372544\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "o98nPOcyVC5H",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def get_images(number=10):\n",
        "    for x in range(number):\n",
        "        attn_list = list(evaluator.attn_log[17][i][x + 1] for i in range(4))\n",
        "        fname = 'attn_vis_{}.png'.format(x + 1)\n",
        "        attn_list.append(fname)\n",
        "        print(len(attn_list))\n",
        "        evaluator.visualize_attn(*attn_list)\n",
        "        plt.savefig(fname)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "lHb_elrebDEa",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 823
        },
        "outputId": "ba19122b-44cf-4d99-d01f-386a4f103167"
      },
      "cell_type": "code",
      "source": [
        "get_images(2)"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "5\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAY0AAAFrCAYAAAAtutVOAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
            "text/plain": [
              "<Figure size 576x396 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "5\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 576x396 with 0 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAZEAAAF3CAYAAABkPHbIAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nItIZiwgREemMRYSIiHTGIkJERDr7P2pewnqtitTHAAAAAElFTkSuQmCC\n",
            "text/plain": [
              "<Figure size 576x396 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 576x396 with 0 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "metadata": {
        "id": "b_iwu1C7cr80",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### Throws cuda out of memory?"
      ]
    },
    {
      "metadata": {
        "id": "29qUadcZbESH",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "translation = evaluator.predict(pred_set, fname='translation.txt', beam_size=10, ignore_eos=True, translate=True)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "vZ51Z8iScdef",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 13617
        },
        "outputId": "90e72cbf-3a95-4a30-ce2c-0f31aeb96509"
      },
      "cell_type": "code",
      "source": [
        "translation"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[[],\n",
              " [],\n",
              " [],\n",
              " [],\n",
              " [],\n",
              " [],\n",
              " [],\n",
              " [],\n",
              " [],\n",
              " [],\n",
              " [],\n",
              " [],\n",
              " [],\n",
              " [],\n",
              " [],\n",
              " [],\n",
              " [],\n",
              " [],\n",
              " [],\n",
              " [],\n",
              " [],\n",
              " [],\n",
              " [],\n",
              " [],\n",
              " [],\n",
              " [],\n",
              " [],\n",
              " [],\n",
              " [],\n",
              " [],\n",
              " [],\n",
              " [],\n",
              " [],\n",
              " [],\n",
              " [],\n",
              " [],\n",
              " [],\n",
              " [],\n",
              " [],\n",
              " [],\n",
              " [],\n",
              " [],\n",
              " [],\n",
              " [],\n",
              " [],\n",
              " [],\n",
              " [],\n",
              " [],\n",
              " [],\n",
              " [],\n",
              " [],\n",
              " [],\n",
              " [],\n",
              " [],\n",
              " [],\n",
              " [],\n",
              " [],\n",
              " [],\n",
              " [],\n",
              " [],\n",
              " [],\n",
              " [],\n",
              " [],\n",
              " [],\n",
              " [],\n",
              " [],\n",
              " [],\n",
              " [],\n",
              " [],\n",
              " [],\n",
              " [],\n",
              " [],\n",
              " [],\n",
              " [],\n",
              " [],\n",
              " [],\n",
              " [],\n",
              " [],\n",
              " [],\n",
              " [],\n",
              " [],\n",
              " [],\n",
              " [],\n",
              " [],\n",
              " [],\n",
              " [],\n",
              " [],\n",
              " [],\n",
              " [],\n",
              " [],\n",
              " [],\n",
              " [],\n",
              " [],\n",
              " [],\n",
              " [],\n",
              " [],\n",
              " [],\n",
              " [],\n",
              " [],\n",
              " [],\n",
              " [],\n",
              " [],\n",
              " [],\n",
              " [],\n",
              " [],\n",
              " [],\n",
              " [],\n",
              " [],\n",
              " [],\n",
              " [],\n",
              " [],\n",
              " [],\n",
              " [],\n",
              " [],\n",
              " [],\n",
              " [],\n",
              " [],\n",
              " [],\n",
              " [],\n",
              " [],\n",
              " [],\n",
              " [],\n",
              " [],\n",
              " [],\n",
              " [],\n",
              " [],\n",
              " [],\n",
              " [],\n",
              " [],\n",
              " [],\n",
              " [],\n",
              " [],\n",
              " [],\n",
              " [],\n",
              " [],\n",
              " [],\n",
              " [],\n",
              " [],\n",
              " [],\n",
              " [],\n",
              " [],\n",
              " [],\n",
              " [],\n",
              " [],\n",
              " [],\n",
              " [],\n",
              " [],\n",
              " [],\n",
              " [],\n",
              " [],\n",
              " [],\n",
              " [],\n",
              " [],\n",
              " [],\n",
              " [],\n",
              " [],\n",
              " [],\n",
              " [],\n",
              " [],\n",
              " [],\n",
              " [],\n",
              " [],\n",
              " [],\n",
              " [],\n",
              " [],\n",
              " [],\n",
              " [],\n",
              " [],\n",
              " [],\n",
              " [],\n",
              " [],\n",
              " [],\n",
              " [],\n",
              " [],\n",
              " [],\n",
              " [],\n",
              " [],\n",
              " [],\n",
              " [],\n",
              " [],\n",
              " [],\n",
              " [],\n",
              " [],\n",
              " [],\n",
              " [],\n",
              " [],\n",
              " [],\n",
              " [],\n",
              " [],\n",
              " [],\n",
              " [],\n",
              " [],\n",
              " [],\n",
              " [],\n",
              " [],\n",
              " [],\n",
              " [],\n",
              " [],\n",
              " [],\n",
              " [],\n",
              " [],\n",
              " [],\n",
              " [],\n",
              " [],\n",
              " [],\n",
              " [],\n",
              " [],\n",
              " [],\n",
              " [],\n",
              " [],\n",
              " [],\n",
              " [],\n",
              " [],\n",
              " [],\n",
              " [],\n",
              " [],\n",
              " [],\n",
              " [],\n",
              " [],\n",
              " [],\n",
              " [],\n",
              " [],\n",
              " [],\n",
              " [],\n",
              " [],\n",
              " [],\n",
              " [],\n",
              " [],\n",
              " [],\n",
              " [],\n",
              " [],\n",
              " [],\n",
              " [],\n",
              " [],\n",
              " [],\n",
              " [],\n",
              " [],\n",
              " [],\n",
              " [],\n",
              " [],\n",
              " [],\n",
              " [],\n",
              " [],\n",
              " [],\n",
              " [],\n",
              " [],\n",
              " [],\n",
              " [],\n",
              " [],\n",
              " [],\n",
              " [],\n",
              " [],\n",
              " [],\n",
              " [],\n",
              " [],\n",
              " [],\n",
              " [],\n",
              " [],\n",
              " [],\n",
              " [],\n",
              " [],\n",
              " [],\n",
              " [],\n",
              " [],\n",
              " [],\n",
              " [],\n",
              " [],\n",
              " [],\n",
              " [],\n",
              " [],\n",
              " [],\n",
              " [],\n",
              " [],\n",
              " [],\n",
              " [],\n",
              " [],\n",
              " [],\n",
              " [],\n",
              " [],\n",
              " [],\n",
              " [],\n",
              " [],\n",
              " [],\n",
              " [],\n",
              " [],\n",
              " [],\n",
              " [],\n",
              " [],\n",
              " [],\n",
              " [],\n",
              " [],\n",
              " [],\n",
              " [],\n",
              " [],\n",
              " [],\n",
              " [],\n",
              " [],\n",
              " [],\n",
              " [],\n",
              " [],\n",
              " [],\n",
              " [],\n",
              " [],\n",
              " [],\n",
              " [],\n",
              " [],\n",
              " [],\n",
              " [],\n",
              " [],\n",
              " [],\n",
              " [],\n",
              " [],\n",
              " [],\n",
              " [],\n",
              " [],\n",
              " [],\n",
              " [],\n",
              " [],\n",
              " [],\n",
              " [],\n",
              " [],\n",
              " [],\n",
              " [],\n",
              " [],\n",
              " [],\n",
              " [],\n",
              " [],\n",
              " [],\n",
              " [],\n",
              " [],\n",
              " [],\n",
              " [],\n",
              " [],\n",
              " [],\n",
              " [],\n",
              " [],\n",
              " [],\n",
              " [],\n",
              " [],\n",
              " [],\n",
              " [],\n",
              " [],\n",
              " [],\n",
              " [],\n",
              " [],\n",
              " [],\n",
              " [],\n",
              " [],\n",
              " [],\n",
              " [],\n",
              " [],\n",
              " [],\n",
              " [],\n",
              " [],\n",
              " [],\n",
              " [],\n",
              " [],\n",
              " [],\n",
              " [],\n",
              " [],\n",
              " [],\n",
              " [],\n",
              " [],\n",
              " [],\n",
              " [],\n",
              " [],\n",
              " [],\n",
              " [],\n",
              " [],\n",
              " [],\n",
              " [],\n",
              " [],\n",
              " [],\n",
              " [],\n",
              " [],\n",
              " [],\n",
              " [],\n",
              " [],\n",
              " [],\n",
              " [],\n",
              " [],\n",
              " [],\n",
              " [],\n",
              " [],\n",
              " [],\n",
              " [],\n",
              " [],\n",
              " [],\n",
              " [],\n",
              " [],\n",
              " [],\n",
              " [],\n",
              " [],\n",
              " [],\n",
              " [],\n",
              " [],\n",
              " [],\n",
              " [],\n",
              " [],\n",
              " [],\n",
              " [],\n",
              " [],\n",
              " [],\n",
              " [],\n",
              " [],\n",
              " [],\n",
              " [],\n",
              " [],\n",
              " [],\n",
              " [],\n",
              " [],\n",
              " [],\n",
              " [],\n",
              " [],\n",
              " [],\n",
              " [],\n",
              " [],\n",
              " [],\n",
              " [],\n",
              " [],\n",
              " [],\n",
              " [],\n",
              " [],\n",
              " [],\n",
              " [],\n",
              " [],\n",
              " [],\n",
              " [],\n",
              " [],\n",
              " [],\n",
              " [],\n",
              " [],\n",
              " [],\n",
              " [],\n",
              " [],\n",
              " [],\n",
              " [],\n",
              " [],\n",
              " [],\n",
              " [],\n",
              " [],\n",
              " [],\n",
              " [],\n",
              " [],\n",
              " [],\n",
              " [],\n",
              " [],\n",
              " [],\n",
              " [],\n",
              " [],\n",
              " [],\n",
              " [],\n",
              " [],\n",
              " [],\n",
              " [],\n",
              " [],\n",
              " [],\n",
              " [],\n",
              " [],\n",
              " [],\n",
              " [],\n",
              " [],\n",
              " [],\n",
              " [],\n",
              " [],\n",
              " [],\n",
              " [],\n",
              " [],\n",
              " [],\n",
              " [],\n",
              " [],\n",
              " [],\n",
              " [],\n",
              " [],\n",
              " [],\n",
              " [],\n",
              " [],\n",
              " [],\n",
              " [],\n",
              " [],\n",
              " [],\n",
              " [],\n",
              " [],\n",
              " [],\n",
              " [],\n",
              " [],\n",
              " [],\n",
              " [],\n",
              " [],\n",
              " [],\n",
              " [],\n",
              " [],\n",
              " [],\n",
              " [],\n",
              " [],\n",
              " [],\n",
              " [],\n",
              " [],\n",
              " [],\n",
              " [],\n",
              " [],\n",
              " [],\n",
              " [],\n",
              " [],\n",
              " [],\n",
              " [],\n",
              " [],\n",
              " [],\n",
              " [],\n",
              " [],\n",
              " [],\n",
              " [],\n",
              " [],\n",
              " [],\n",
              " [],\n",
              " [],\n",
              " [],\n",
              " [],\n",
              " [],\n",
              " [],\n",
              " [],\n",
              " [],\n",
              " [],\n",
              " [],\n",
              " [],\n",
              " [],\n",
              " [],\n",
              " [],\n",
              " [],\n",
              " [],\n",
              " [],\n",
              " [],\n",
              " [],\n",
              " [],\n",
              " [],\n",
              " [],\n",
              " [],\n",
              " [],\n",
              " [],\n",
              " [],\n",
              " [],\n",
              " [],\n",
              " [],\n",
              " [],\n",
              " [],\n",
              " [],\n",
              " [],\n",
              " [],\n",
              " [],\n",
              " [],\n",
              " [],\n",
              " [],\n",
              " [],\n",
              " [],\n",
              " [],\n",
              " [],\n",
              " [],\n",
              " [],\n",
              " [],\n",
              " [],\n",
              " [],\n",
              " [],\n",
              " [],\n",
              " [],\n",
              " [],\n",
              " [],\n",
              " [],\n",
              " [],\n",
              " [],\n",
              " [],\n",
              " [],\n",
              " [],\n",
              " [],\n",
              " [],\n",
              " [],\n",
              " [],\n",
              " [],\n",
              " [],\n",
              " [],\n",
              " [],\n",
              " [],\n",
              " [],\n",
              " [],\n",
              " [],\n",
              " [],\n",
              " [],\n",
              " [],\n",
              " [],\n",
              " [],\n",
              " [],\n",
              " [],\n",
              " [],\n",
              " [],\n",
              " [],\n",
              " [],\n",
              " [],\n",
              " [],\n",
              " [],\n",
              " [],\n",
              " [],\n",
              " [],\n",
              " [],\n",
              " [],\n",
              " [],\n",
              " [],\n",
              " [],\n",
              " [],\n",
              " [],\n",
              " [],\n",
              " [],\n",
              " [],\n",
              " [],\n",
              " [],\n",
              " [],\n",
              " [],\n",
              " [],\n",
              " [],\n",
              " [],\n",
              " [],\n",
              " [],\n",
              " [],\n",
              " [],\n",
              " [],\n",
              " [],\n",
              " [],\n",
              " [],\n",
              " [],\n",
              " [],\n",
              " [],\n",
              " [],\n",
              " [],\n",
              " [],\n",
              " [],\n",
              " [],\n",
              " [],\n",
              " [],\n",
              " [],\n",
              " [],\n",
              " [],\n",
              " [],\n",
              " [],\n",
              " [],\n",
              " [],\n",
              " [],\n",
              " [],\n",
              " [],\n",
              " [],\n",
              " [],\n",
              " [],\n",
              " [],\n",
              " [],\n",
              " [],\n",
              " [],\n",
              " [],\n",
              " [],\n",
              " [],\n",
              " [],\n",
              " [],\n",
              " [],\n",
              " [],\n",
              " [],\n",
              " [],\n",
              " [],\n",
              " [],\n",
              " [],\n",
              " [],\n",
              " [],\n",
              " [],\n",
              " [],\n",
              " [],\n",
              " [],\n",
              " [],\n",
              " [],\n",
              " [],\n",
              " [],\n",
              " [],\n",
              " [],\n",
              " [],\n",
              " [],\n",
              " [],\n",
              " [],\n",
              " [],\n",
              " [],\n",
              " [],\n",
              " [],\n",
              " [],\n",
              " [],\n",
              " [],\n",
              " [],\n",
              " [],\n",
              " [],\n",
              " [],\n",
              " [],\n",
              " [],\n",
              " [],\n",
              " [],\n",
              " [],\n",
              " [],\n",
              " [],\n",
              " [],\n",
              " [],\n",
              " [],\n",
              " [],\n",
              " [],\n",
              " [],\n",
              " [],\n",
              " [],\n",
              " [],\n",
              " [],\n",
              " [],\n",
              " [],\n",
              " [],\n",
              " [],\n",
              " [],\n",
              " [],\n",
              " [],\n",
              " [],\n",
              " [],\n",
              " [],\n",
              " [],\n",
              " [],\n",
              " [],\n",
              " [],\n",
              " [],\n",
              " [],\n",
              " [],\n",
              " [],\n",
              " [],\n",
              " [],\n",
              " [],\n",
              " [],\n",
              " [],\n",
              " [],\n",
              " [],\n",
              " [],\n",
              " [],\n",
              " [],\n",
              " [],\n",
              " [],\n",
              " [],\n",
              " [],\n",
              " [],\n",
              " [],\n",
              " [],\n",
              " [],\n",
              " [],\n",
              " [],\n",
              " [],\n",
              " [],\n",
              " [],\n",
              " [],\n",
              " [],\n",
              " [],\n",
              " [],\n",
              " [],\n",
              " [],\n",
              " [],\n",
              " [],\n",
              " [],\n",
              " [],\n",
              " [],\n",
              " [],\n",
              " [],\n",
              " [],\n",
              " [],\n",
              " [],\n",
              " [],\n",
              " [],\n",
              " [],\n",
              " [],\n",
              " [],\n",
              " [],\n",
              " [],\n",
              " [],\n",
              " [],\n",
              " [],\n",
              " [],\n",
              " [],\n",
              " [],\n",
              " [],\n",
              " [],\n",
              " [],\n",
              " [],\n",
              " [],\n",
              " [],\n",
              " [],\n",
              " [],\n",
              " [],\n",
              " [],\n",
              " [],\n",
              " [],\n",
              " [],\n",
              " [],\n",
              " [],\n",
              " [],\n",
              " [],\n",
              " [],\n",
              " [],\n",
              " [],\n",
              " []]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 18
        }
      ]
    },
    {
      "metadata": {
        "id": "K1R1Zhnntxw6",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}